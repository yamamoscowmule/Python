{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_reshape.csv\",sep = \",\")\n",
    "df_test = pd.read_csv(\"test_reshape.csv\",sep = \",\")\n",
    "\n",
    "df_train.drop([\"Parch\",\"Fare\"],axis = 1,inplace = True)\n",
    "df_test.drop([\"Parch\",\"Fare\"],axis = 1,inplace = True)\n",
    "\n",
    "df_train[\"Dead\"] = 0.0\n",
    "df_train =  df_train.iloc[:,[0,5,1,2,3,4]]\n",
    "df_train[\"Dead\"][df_train[\"Survived\"] == 0.0] =1.0\n",
    "\n",
    "df_test[\"Survived\"] = 0.0\n",
    "df_test[\"Dead\"] = 0.0\n",
    "df_test =  df_test.iloc[:,[4,5,0,1,2,3]]\n",
    "\n",
    "df_train = df_train.astype(\"float64\")\n",
    "df_test = df_test.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Dead  Pclass  Sex   Age  SibSp\n",
      "0       0.0   1.0     3.0  0.0  22.0    1.0\n",
      "1       1.0   0.0     1.0  1.0  38.0    1.0\n",
      "2       1.0   0.0     3.0  1.0  26.0    0.0\n",
      "3       1.0   0.0     1.0  1.0  35.0    1.0\n",
      "4       0.0   1.0     3.0  0.0  35.0    0.0\n",
      "   Survived  Dead  Pclass  Sex   Age  SibSp\n",
      "0       0.0   0.0     3.0  0.0  34.5    0.0\n",
      "1       0.0   0.0     3.0  1.0  47.0    1.0\n",
      "2       0.0   0.0     2.0  0.0  62.0    0.0\n",
      "3       0.0   0.0     3.0  0.0  27.0    0.0\n",
      "4       0.0   0.0     3.0  1.0  22.0    1.0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    float64\n",
       "Dead        float64\n",
       "Pclass      float64\n",
       "Sex         float64\n",
       "Age         float64\n",
       "SibSp       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(-1, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm = scaler.transform(df_train)\n",
    "df_test_norm = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        ,  1.        , -1.        , -0.14350339,\n",
       "        -1.        ],\n",
       "       [-1.        , -1.        ,  1.        ,  1.        ,  0.17064589,\n",
       "        -0.75      ],\n",
       "       [-1.        , -1.        ,  0.        , -1.        ,  0.54762503,\n",
       "        -1.        ],\n",
       "       ...,\n",
       "       [-1.        , -1.        ,  1.        , -1.        , -0.04297562,\n",
       "        -1.        ],\n",
       "       [-1.        , -1.        ,  1.        , -1.        , -0.24974641,\n",
       "        -1.        ],\n",
       "       [-1.        , -1.        ,  1.        , -1.        , -0.24974641,\n",
       "        -0.75      ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_norm[:,2:]\n",
    "Y_train = df_train_norm[:,(0,1)]\n",
    "X_test = df_test_norm[:,1:]\n",
    "Y_test = df_test_norm[:,(0,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [ 1., -1.],\n",
       "       [ 1., -1.],\n",
       "       ...,\n",
       "       [-1.,  1.],\n",
       "       [ 1., -1.],\n",
       "       [-1.,  1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#トレーニングデータの列数\n",
    "n_stocks = X_train.shape[1]\n",
    " \n",
    "# ニューロンの数を設定\n",
    "n_neurons_1 = 256\n",
    "n_neurons_2 = 128\n",
    "  \n",
    "# プレースホルダーの作成（データ格納予定地的な）\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_stocks])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None,2])\n",
    " \n",
    "# 初期化\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "#重み、バイアスのオブジェクト(?)を生成\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_stocks, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "\n",
    "#同様に出力の重みも,\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_2, 1]))\n",
    "bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "# 隠れ層の設定（ReLU＝活性化関数）\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    " \n",
    "# 出力層の設定\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_2, W_out), bias_out))\n",
    "\n",
    "#コスト関数\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# 最適化関数\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "    \n",
    "# 初期化\n",
    "net.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (891, 2) for Tensor 'Placeholder_21:0', which has shape '(?,)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-38feac242cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#summary_writer.add_summary(loss_val,i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1149\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1150\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (891, 2) for Tensor 'Placeholder_21:0', which has shape '(?,)'"
     ]
    }
   ],
   "source": [
    "# ニューラルネットワークの設定\n",
    "batch_size = 128\n",
    "mse_train = []\n",
    "mse_test = []\n",
    " \n",
    "# 訓練開始！5000回の反復処理\n",
    "epochs = 5000\n",
    "for e in range(epochs):\n",
    "    net.run(opt, feed_dict={X: X_train, Y: Y_train})\n",
    "    loss_val = net.run(mse,feed_dict={X: X_train,Y:Y_train})\n",
    "    #summary_writer.add_summary(loss_val,i)\n",
    "    if e % 1000 == 0:\n",
    "        print(\"Step: %d, Loss: %f\" % (e,loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = net.run(out, feed_dict={X: X_test})\n",
    "pred_test = np.concatenate((pred_test.T, X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_inv = scaler.inverse_transform(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.04084516e-02,  3.00000000e+00,  0.00000000e+00,\n",
       "         3.45000000e+01,  0.00000000e+00],\n",
       "       [-3.60476971e-02,  3.00000000e+00,  1.00000000e+00,\n",
       "         4.70000000e+01,  1.00000000e+00],\n",
       "       [ 8.97931397e-01,  2.00000000e+00,  0.00000000e+00,\n",
       "         6.20000000e+01,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 2.08662450e-02,  3.00000000e+00,  0.00000000e+00,\n",
       "         3.85000000e+01,  0.00000000e+00],\n",
       "       [ 1.41812235e-01,  3.00000000e+00,  0.00000000e+00,\n",
       "         3.02725904e+01,  0.00000000e+00],\n",
       "       [ 1.19436294e-01,  3.00000000e+00,  0.00000000e+00,\n",
       "         3.02725904e+01,  1.00000000e+00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp\n",
       "0       0.0     3.0  0.0  34.5    0.0\n",
       "1       0.0     3.0  1.0  47.0    1.0\n",
       "2       0.0     2.0  0.0  62.0    0.0\n",
       "3       0.0     3.0  0.0  27.0    0.0\n",
       "4       0.0     3.0  1.0  22.0    1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  0. 21.  2.]\n",
      "[ 0.  3.  0. 21.  2.]\n",
      "[-6.08420372e-03  3.00000000e+00  0.00000000e+00  2.10000000e+01\n",
      "  2.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "test_inv = np.concatenate((Y_test, X_test), axis=1)\n",
    "\n",
    "test_inv = scaler.inverse_transform(test_inv)\n",
    "\n",
    "# テストデータの最後のデータ（正規化前）\n",
    "print(df_test.values[9])\n",
    " \n",
    "# テストデータの最後のデータ（正規化を戻した後）\n",
    "print(test_inv[9])\n",
    " \n",
    "# モデルが予測したデータ\n",
    "print(pred_inv[:][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
